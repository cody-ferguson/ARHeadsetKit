@Tutorial(time: 45) {
    @XcodeRequirement(
            title: "Xcode 13", 
            destination: "https://developer.apple.com/download/")
    
    @Intro(title: "Working with AR Objects") {
        Coming soon!
        Learn how to utilize ARHeadsetKit's renderer hierarchy and draw shapes that respond to the world around them.
        
        Download the project files to begin building this project, and follow the steps below.
        
        @Image(source: "1-3-image-1-1-intro.jpg", alt: "Different types of shapes rendering.")
    }
    
    @Section(title: "Utilize the Central Renderer") {
        @ContentAndMedia {
            ARHeadsetKit renders an AR experience through a hierarchy of renderers. At the top level, the ``ARHeadsetKit/MainRenderer`` receives data about your surroundings from ARKit. It calls several delegate renderers, which perform tasks such as hand tracking and drawing objects. By conforming to the ``ARHeadsetKit/DelegateRenderer`` protocol, these renderers can communicate with each other.
            
            Every delegate renderer automatically gains access to several properties. For example, the `MyRenderer` class conforms to ``ARHeadsetKit/CustomRenderer``, which in turn conforms to `DelegateRenderer`. In previous tutorials, it rendered 3D objects using the ``ARHeadsetKit/DelegateRenderer/centralRenderer`` property. Now, you will learn how to use the ``ARHeadsetKit/CentralRenderer``.
            
            @Image(source: "1-3-image-0-1.png", alt: "Diagram of renderers calling each other.")
        }
        
        @ContentAndMedia {
            The `CentralRenderer` receives requests to render AR objects from other renderers. It culls invisible objects and removes details the user won't notice. Then, it commands the GPU to render the objects.

            To begin, you'll learn about the types of shapes the `CentralRenderer` can draw.

        }
        
        @Steps {
            @Step {
                In the project navigator, select `MyRenderer.swift`.
                
                @Code(name: "MyRenderer.swift", file: "1-2-creating-code-3-6.swift")
            }
            
            @Step {
                Loop over every case in the ``ARHeadsetKit/ARShapeType`` enumeration. Place the rendering code inside the new loop.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-1.swift")
            }
            
            @Step {
                Shrink the rendered objects from 0.2 to 0.1 meters in each dimension.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-2.swift")
            }
            
            @Step {
                Declare a 3D position vector outside the loop. Set it to the origin.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-3.swift")
            }
            
            @Step {
                In the ``ARHeadsetKit/ARObject`` initializer, replace `.cone` with `shapeType` and `[0.0, 0.0, 0.0]` with the position.
                
                Now, a new type of object will appear in each iteration.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-4.swift")
            }
            
            @Step {
                Add 0.15 meters of spacing between each object in the X direction.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-5.swift")
            }
            
            @Step {
                Position your device so that its right side faces an open room. Then, launch the app.
                
                @Image(source: "1-3-image-1-1.jpg", alt: "Different types of shapes rendering.")
            }
        }
    }
    
    @Section(title: "Fuse AR Objects") {
        @ContentAndMedia {
            Up to this point, all AR objects have been separated from each other. With scaling, rotation, and translation, they can combine into compound objects.
            
            You'll create an arrow by fusing a cylinder and a cone, while learning a new initializer for round objects.
        }
        
        @Steps {
            @Step {
                Delete the rendering code from the previous section.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-1.swift", previousFile: "1-3-creating-code-1-5.swift")
            }
            
            @Step {
                Determine the color of AR objects.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-2.swift")
            }
            
            @Step {
                State the start and end of the arrow. It points from the origin to 0.2 meters along the Y axis.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-3.swift")
            }
            
            @Step {
                Find the difference between the end and the start. Then, pass it into the `normalize(_:)` function and assign it to `arrowDirection`.
                
                Normalizing a vector extends its length to one meter. This makes the vector's size easy to change.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-4.swift")
            }
            
            @Step {
                Calculate where the arrow's tip starts. Multiply its direction by 0.1 meters, then subtract from its end.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-5.swift")
            }
            
            @Step {
                Using a new ``ARHeadsetKit/ARObject`` initializer, create a cone with a diameter of 0.07 meters. Set the bottom to `tipStart` and the top to `arrowEnd`.
                
                This initializer may return `nil` when the bottom and top are the same. Always account for this situation, unless you can guarantee it won't happen.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-6.swift")
            }
            
            @Step {
                Render the rest of the arrow using a cylinder object. Define its endpoints as `arrowStart` and `tipStart`, then set its diameter to 0.05 meters.
                
                > Tip: When a control flow element spans several lines, place the opening bracket on a new line. In this step, the extra space visually separates the object initializer from the call to ``ARHeadsetKit/CentralRenderer/render(object:)``.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-2-7.swift")
            }
            
            @Step {
                Launch the app and view the upward-facing arrow.
                
                @Image(source: "1-3-image-2-1.jpg", alt: "A red arrow pointing upward.")
            }
        }
    }
    
    @Section(title: "Animate Objects") {
        @ContentAndMedia {
            When AR objects move around and respond to their environment, they become more engaging. Using animation, you can incorporate motion into your app.
            
            Almost every frame (1/60 of a second), the `MainRenderer` updates its delegate renderers' resources. To animate the red arrow, increment an integer every time your custom renderer executes ``ARHeadsetKit/CustomRenderer/updateResources()``.
        }
        
<!--    Rotate the arrow sideways   -->
        
        @Steps {
            n/a
        }
    }
    
    @Section(title: "Move with the Camera") {
        @ContentAndMedia {
            The `MainRenderer` provides delegate renderers with several pieces of information about the surrounding world. Transform matrices such as ``ARHeadsetKit/DelegateRenderer/cameraToWorldTransform`` tell where the iPhone or iPad is located in the real world.
            
            Read the camera's direction from a transform matrix, and use it to place an `ARObject` the user can always see. 
        }
        
<!--    Make the arrow stay in the center of vision.    -->
        
        @Steps {
            n/a
        }
    }
}
