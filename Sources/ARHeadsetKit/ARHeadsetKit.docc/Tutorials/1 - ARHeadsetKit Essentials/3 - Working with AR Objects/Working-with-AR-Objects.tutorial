@Tutorial(time: 30) {
    @XcodeRequirement(
            title: "Xcode 13", 
            destination: "https://developer.apple.com/download/")
    
    @Intro(title: "Working with AR Objects") {
        Coming soon!
        Learn how to utilize ARHeadsetKit's renderer hierarchy and draw shapes that respond to the world around them.
        
        Download the project files to begin building this project, and follow the steps below.
        
        @Image(source: "1-3-image-1-1-intro.jpg", alt: "Different types of shapes rendering.")
    }
    
    @Section(title: "Utilizing the Central Renderer") {
        @ContentAndMedia {
            ARHeadsetKit renders an AR experience through a hierarchy of renderers. At the top level, the ``ARHeadsetKit/MainRenderer`` receives data about your surroundings from ARKit. It calls several delegate renderers, which perform tasks such as hand tracking and drawing objects. By conforming to the ``ARHeadsetKit/DelegateRenderer`` protocol, these renderers can communicate with each other.
            
            Every delegate renderer automatically gains access to several properties. For example, the `MyRenderer` class conforms to ``ARHeadsetKit/CustomRenderer``, which in turn conforms to `DelegateRenderer`. In previous tutorials, it rendered 3D objects using the ``ARHeadsetKit/DelegateRenderer/centralRenderer`` property. Now, you will learn how to use the ``ARHeadsetKit/CentralRenderer``.
            
            @Image(source: "1-3-image-0-1.png", alt: "Diagram of renderers calling each other.")
        }
        
        @ContentAndMedia {
            The `CentralRenderer` receives requests to render AR objects from other renderers. It culls invisible objects and removes details the user won't notice. Then, it commands the GPU to render the objects.

            To begin, you'll learn about the types of shapes the `CentralRenderer` can draw.

        }
        
        @Steps {
            @Step {
                In the project navigator, select `MyRenderer.swift`.
                
                @Code(name: "MyRenderer.swift", file: "1-2-creating-code-3-6.swift")
            }
            
            @Step {
                Loop over every case in the ``ARHeadsetKit/ARShapeType`` enumeration. Place the rendering code inside the new loop.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-1.swift")
            }
            
            @Step {
                Shrink the rendered objects from 0.2 to 0.1 meters in each dimension.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-2.swift")
            }
            
            @Step {
                Declare a 3D position vector outside the loop. Set it to the origin.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-3.swift")
            }
            
            @Step {
                In the ``ARHeadsetKit/ARObject`` initializer, replace `.cone` with `shapeType` and `[0.0, 0.0, 0.0]` with the position.
                
                Now, a new type of object will appear in each iteration.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-4.swift")
            }
            
            @Step {
                Add 0.15 meters of spacing between each object in the X direction.
                
                @Code(name: "MyRenderer.swift", file: "1-3-creating-code-1-5.swift")
            }
            
            @Step {
                Position your device so that its right side faces an open room. Then, launch the app.
                
                @Image(source: "1-3-image-1-1.jpg", alt: "Different types of shapes rendering.")
            }
        }
    }
    
    @Section(title: "Fusing AR Objects") {
        @ContentAndMedia {
            Up to this point, all AR objects have been separated from each other. Using scaling, rotation, and translation, you can combine them into compound objects.
        }
        
<!--    Create an arrow, then a wheel of four arrows    -->
        
        @Steps {
            n/a
        }
    }
    
    @Section(title: "Animating Objects") {
        @ContentAndMedia {
            When AR objects move around and respond to their environment, they become more engaging. Using animation, you can easily incorporate motion into your app.
            
            Almost every frame (1/60 of a second), the `MainRenderer` updates its delegate renderers' resources. To animate AR objects, increment an integer every time your custom renderer executes ``ARHeadsetKit/CustomRenderer/updateResources()``.
        }
        
<!--    Animate the wheel or arrows    -->
<!--    Make its color change over time   -->
        
        @Steps {
            n/a
        }
    }
    
    @Section(title: "Moving with the Camera") {
        @ContentAndMedia {
            The `MainRenderer` provides delegate renderers with several pieces of information about the surrounding world. Transform matrices such as ``ARHeadsetKit/DelegateRenderer/cameraToWorldTransform`` tell where the iPhone or iPad is located in the real world.
            
            Read the camera's direction from a transform matrix, and use it to place an `ARObject` the user can always see. 
        }
        
<!--    Make the wheel of arrows stay in the center of vision.    -->
        
        @Steps {
            n/a
        }
    }
}
